{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23c3408a-de0a-412f-9b42-f089c94c271c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 3748 images\n",
      "Valid set: 1071 images\n",
      "Test set: 533 images\n",
      "Found 3748 validated image filenames belonging to 2 classes.\n",
      "Found 1071 validated image filenames belonging to 2 classes.\n",
      "Found 533 validated image filenames belonging to 2 classes.\n",
      "Train generator samples: 3748\n",
      "Valid generator samples: 1071\n",
      "Test generator samples: 533\n",
      "Train set - defect: 3321, no_defect: 427\n",
      "Valid set - defect: 942, no_defect: 129\n",
      "Test set - defect: 470, no_defect: 63\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# 数据路径\n",
    "train_dir = r'C:\\Users\\xiaog\\Desktop\\Project\\Datasets\\dataset\\dataset 4\\Data Files\\train'\n",
    "valid_dir = r'C:\\Users\\xiaog\\Desktop\\Project\\Datasets\\dataset\\dataset 4\\Data Files\\valid'\n",
    "test_dir = r'C:\\Users\\xiaog\\Desktop\\Project\\Datasets\\dataset\\dataset 4\\Data Files\\test'\n",
    "# 解析XML文件，获取标签\n",
    "def get_label_from_xml(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    objects = root.findall('object')\n",
    "\n",
    "    # 如果存在 \"thermal_defect\"，返回 1，否则返回 0\n",
    "    for obj in objects:\n",
    "        if obj.find('name').text == 'thermal_defect':\n",
    "            return \"1\"  # 必须是字符串\n",
    "\n",
    "    return \"0\"  # 也必须是字符串\n",
    "\n",
    "\n",
    "def count_defects_in_directory(data_dir):\n",
    "    with_defect = 0\n",
    "    without_defect = 0\n",
    "    \n",
    "    for xml_file in os.listdir(data_dir):\n",
    "        if xml_file.endswith('.xml'):\n",
    "            xml_path = os.path.join(data_dir, xml_file)\n",
    "            label = get_label_from_xml(xml_path)\n",
    "            \n",
    "            if label == \"1\":\n",
    "                with_defect += 1\n",
    "            else:\n",
    "                without_defect += 1\n",
    "    \n",
    "    return with_defect, without_defect\n",
    "\n",
    "# 统计数据集中有缺陷和无缺陷的图像数量\n",
    "train_with_defect, train_without_defect = count_defects_in_directory(train_dir)\n",
    "valid_with_defect, valid_without_defect = count_defects_in_directory(valid_dir)\n",
    "test_with_defect, test_without_defect = count_defects_in_directory(test_dir)\n",
    "\n",
    "\n",
    "# 处理数据，返回 DataFrame（包含文件路径和标签）\n",
    "def create_dataframe(data_dir):\n",
    "    data = []\n",
    "    \n",
    "    for xml_file in os.listdir(data_dir):\n",
    "        if xml_file.endswith('.xml'):\n",
    "            xml_path = os.path.join(data_dir, xml_file)\n",
    "            img_path = xml_path.replace('.xml', '.jpg')  # 假设图像文件与 XML 同名\n",
    "            \n",
    "            if os.path.exists(img_path):  # 确保图像文件存在\n",
    "                label = get_label_from_xml(xml_path)  # 确保是字符串\n",
    "                data.append([img_path, label])\n",
    "    \n",
    "    return pd.DataFrame(data, columns=['filepath', 'label'])\n",
    "\n",
    "# 创建数据集 DataFrame\n",
    "train_df = create_dataframe(train_dir)\n",
    "valid_df = create_dataframe(valid_dir)\n",
    "test_df = create_dataframe(test_dir)\n",
    "\n",
    "# 统计数据\n",
    "print(f\"Train set: {len(train_df)} images\")\n",
    "print(f\"Valid set: {len(valid_df)} images\")\n",
    "print(f\"Test set: {len(test_df)} images\")\n",
    "\n",
    "# 训练数据增强（仅用于训练集）\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # 归一化\n",
    "    rotation_range=30,  # 随机旋转\n",
    "    width_shift_range=0.1,  # 水平平移\n",
    "    height_shift_range=0.1,  # 垂直平移\n",
    "    shear_range=0.2,  # 剪切变换\n",
    "    zoom_range=0.2,  # 缩放\n",
    "    horizontal_flip=True,  # 随机水平翻转\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# 验证 & 测试数据（仅归一化，不做增强）\n",
    "valid_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "\n",
    "# 生成训练数据\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(128, 128),\n",
    "    batch_size=16,\n",
    "    class_mode=\"categorical\"  # 适用于二分类任务\n",
    ")\n",
    "\n",
    "# 生成验证数据\n",
    "valid_generator = valid_test_datagen.flow_from_dataframe(\n",
    "    dataframe=valid_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(128, 128),\n",
    "    batch_size=16,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "# 生成测试数据\n",
    "test_generator = valid_test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(128, 128),\n",
    "    batch_size=16,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False  # 测试数据不打乱顺序\n",
    ")\n",
    "\n",
    "# 输出数据量\n",
    "print(f\"Train generator samples: {train_generator.samples}\")\n",
    "print(f\"Valid generator samples: {valid_generator.samples}\")\n",
    "print(f\"Test generator samples: {test_generator.samples}\")\n",
    "\n",
    "# 输出结果\n",
    "print(f\"Train set - defect: {train_with_defect}, no_defect: {train_without_defect}\")\n",
    "print(f\"Valid set - defect: {valid_with_defect}, no_defect: {valid_without_defect}\")\n",
    "print(f\"Test set - defect: {test_with_defect}, no_defect: {test_without_defect}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f895ccb5-71fd-42e4-aae0-6dd45e779572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 128, 128, 3)  0          ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 128, 128, 32  128         ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 128, 128, 32  896         ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 128, 128, 32  2432        ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 128, 128, 32  128         ['max_pooling2d_5[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 128, 128, 12  0           ['conv2d_12[0][0]',              \n",
      "                                8)                                'conv2d_13[0][0]',              \n",
      "                                                                  'conv2d_14[0][0]',              \n",
      "                                                                  'conv2d_15[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 64, 64, 128)  0          ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 64, 64, 128)  0          ['max_pooling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 64, 64, 64)   8256        ['max_pooling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 64, 64, 64)   73792       ['max_pooling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 64, 64, 64)   204864      ['max_pooling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 64, 64, 64)   8256        ['max_pooling2d_7[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 64, 64, 256)  0           ['conv2d_16[0][0]',              \n",
      "                                                                  'conv2d_17[0][0]',              \n",
      "                                                                  'conv2d_18[0][0]',              \n",
      "                                                                  'conv2d_19[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPooling2D)  (None, 32, 32, 256)  0          ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPooling2D)  (None, 32, 32, 256)  0          ['max_pooling2d_8[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 32, 32, 128)  32896       ['max_pooling2d_8[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 32, 32, 128)  295040      ['max_pooling2d_8[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 32, 32, 128)  819328      ['max_pooling2d_8[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 32, 32, 128)  32896       ['max_pooling2d_9[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 32, 32, 512)  0           ['conv2d_20[0][0]',              \n",
      "                                                                  'conv2d_21[0][0]',              \n",
      "                                                                  'conv2d_22[0][0]',              \n",
      "                                                                  'conv2d_23[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 512)         0           ['concatenate_5[0][0]']          \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 4, 128)       0           ['global_average_pooling2d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 4, 128)      98816       ['reshape_2[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 4, 128)       0           ['bidirectional_1[0][0]']        \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 4, 1)         129         ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 4)            0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 4)            0           ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)            (None, 4, 1)         0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, 4, 128)       0           ['dropout_2[0][0]',              \n",
      "                                                                  'reshape_3[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1 (Gl  (None, 128)         0           ['multiply_1[0][0]']             \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 64)           8256        ['global_average_pooling1d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 64)           0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 2)            130         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,586,243\n",
      "Trainable params: 1,586,243\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "# # 启用混合精度\n",
    "# policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
    "# tf.keras.mixed_precision.set_global_policy(policy)\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         tf.config.experimental.set_virtual_device_configuration(\n",
    "#             gpus[0],\n",
    "#             [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)]  # 限制为 4GB\n",
    "#         )\n",
    "#         print(\"GPU 内存限制已设置！\")\n",
    "#     except RuntimeError as e:\n",
    "#         print(e)\n",
    "\n",
    "def inception_module(x, filters):\n",
    "    # 1x1卷积分支\n",
    "    conv1x1 = Conv2D(filters, (1,1), padding='same', activation='relu')(x)\n",
    "    \n",
    "    # 3x3卷积分支\n",
    "    conv3x3 = Conv2D(filters, (3,3), padding='same', activation='relu')(x)\n",
    "    \n",
    "    # 5x5卷积分支\n",
    "    conv5x5 = Conv2D(filters, (5,5), padding='same', activation='relu')(x)\n",
    "    \n",
    "    # 池化分支\n",
    "    pool = MaxPooling2D((3,3), strides=(1,1), padding='same')(x)\n",
    "    pool = Conv2D(filters, (1,1), padding='same', activation='relu')(pool)\n",
    "    \n",
    "    # 合并各分支\n",
    "    merged = concatenate([conv1x1, conv3x3, conv5x5, pool], axis=-1)\n",
    "    return merged\n",
    "\n",
    "def attention_block(inputs):\n",
    "    attention = Dense(1, activation='tanh')(inputs)    # (batch_size, seq_length, 1)\n",
    "    attention = Flatten()(attention)                   # (batch_size, seq_length)\n",
    "    attention = Activation('softmax')(attention)       # (batch_size, seq_length)\n",
    "    attention = Reshape((inputs.shape[1], 1))(attention)  # (batch_size, seq_length, 1)\n",
    "    \n",
    "    context = Multiply()([inputs, attention])          # (batch_size, seq_length, features)\n",
    "    return context\n",
    "\n",
    "\n",
    "def build_model(input_shape=(128, 128, 3), num_classes=2):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = inception_module(inputs, 32)\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    x = inception_module(x, 64)\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    x = inception_module(x, 128)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    x = Reshape((-1, 128))(x)  # sequence for LSTM\n",
    "    x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = attention_block(x)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "    # Build the model\n",
    "model = build_model(input_shape=(128, 128, 3), num_classes=2)\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c80bea7-c265-4fb5-a5ea-3f6431689f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "# # 启用混合精度\n",
    "# policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
    "# tf.keras.mixed_precision.set_global_policy(policy)\n",
    "\n",
    "# 定义 Focal Loss\n",
    "def focal_loss(gamma=2., alpha=0.75):\n",
    "    \"\"\"\n",
    "    Focal Loss implementation for binary classification.\n",
    "\n",
    "    Parameters:\n",
    "        gamma (float): Focusing parameter. Default is 2.\n",
    "        alpha (float): Weighting factor for class imbalance. Default is 0.75 for better focusing on less frequent class.\n",
    "\n",
    "    Returns:\n",
    "        loss (function): Focal loss function.\n",
    "    \"\"\"\n",
    "\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        # Clip predictions to avoid log(0)\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1. - K.epsilon())\n",
    "\n",
    "        # Calculate cross entropy\n",
    "        cross_entropy = -y_true * K.log(y_pred)\n",
    "\n",
    "        # Calculate modulating factor (1 - p_t) ^ gamma\n",
    "        modulating_factor = K.pow(1 - y_pred, gamma)\n",
    "\n",
    "        # Calculate the focal loss\n",
    "        loss = alpha * modulating_factor * cross_entropy\n",
    "\n",
    "        return K.sum(loss, axis=-1)\n",
    "\n",
    "    return focal_loss_fixed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8151e696-fd8b-43b7-8ed9-30d55be68125",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "        optimizer=Adam(learning_rate=1e-4),\n",
    "        loss=focal_loss(gamma=2., alpha=0.75),\n",
    "        metrics=[\n",
    "            'accuracy', \n",
    "            Precision(name='precision'), \n",
    "            Recall(name='recall'), \n",
    "            'AUC'\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c5bcab-fcc5-4c71-9a5a-55e9fa2097c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "117/117 [==============================] - 45s 381ms/step - loss: 0.0683 - accuracy: 0.8958 - precision: 0.8958 - recall: 0.8958 - auc: 0.9087 - val_loss: 0.0688 - val_accuracy: 0.8788 - val_precision: 0.8788 - val_recall: 0.8788 - val_auc: 0.9241 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "117/117 [==============================] - 43s 364ms/step - loss: 0.0696 - accuracy: 0.8817 - precision: 0.8817 - recall: 0.8817 - auc: 0.9148 - val_loss: 0.0670 - val_accuracy: 0.8788 - val_precision: 0.8788 - val_recall: 0.8788 - val_auc: 0.9275 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "117/117 [==============================] - 44s 370ms/step - loss: 0.0671 - accuracy: 0.8905 - precision: 0.8905 - recall: 0.8905 - auc: 0.9206 - val_loss: 0.0678 - val_accuracy: 0.8778 - val_precision: 0.8778 - val_recall: 0.8778 - val_auc: 0.9324 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "117/117 [==============================] - 43s 369ms/step - loss: 0.0669 - accuracy: 0.8873 - precision: 0.8873 - recall: 0.8873 - auc: 0.9234 - val_loss: 0.0652 - val_accuracy: 0.8788 - val_precision: 0.8788 - val_recall: 0.8788 - val_auc: 0.9339 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      " 77/117 [==================>...........] - ETA: 11s - loss: 0.0677 - accuracy: 0.8856 - precision: 0.8856 - recall: 0.8856 - auc: 0.9218"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# assume epochs and bacth size\n",
    "epochs = 50\n",
    "batch_size = 32  \n",
    "\n",
    "steps_per_epoch = train_generator.samples // batch_size\n",
    "validation_steps = valid_generator.samples // batch_size\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True),\n",
    "    # ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "\n",
    "# model_checkpoint = ModelCheckpoint(\n",
    "#     # filepath='best_model.h5',  # 保存最优模型的路径\n",
    "#     monitor='val_loss',\n",
    "#     save_best_only=True,\n",
    "#     mode='min',\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,  \n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=validation_steps, \n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e140f4b-f541-4312-a389-73bb82f4a023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f425f2c-ec15-427c-bb76-e8357334e104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2014887-24e5-4048-a33e-c15d995ca427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d163e1f9-1ee8-4b4a-b598-a3545bec585f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4b3459-3ac5-4727-819e-7cd0b909223d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81e087b-809a-4ed6-a57f-7e80f60b4f31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c193e72-616d-46f6-9c9c-3075124bf8dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b3ca1b-cef1-4445-a28c-53c0b238b53d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (python3999)",
   "language": "python",
   "name": "python3999"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
