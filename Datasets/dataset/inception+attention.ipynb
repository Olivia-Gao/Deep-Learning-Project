{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e805d966-bc38-4aa7-ac45-723cbc55e861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# data path\n",
    "train_dir = r'C:\\Users\\xiaog\\Desktop\\Project\\Datasets\\dataset\\split_70_20_10\\train'\n",
    "valid_dir = r'C:\\Users\\xiaog\\Desktop\\Project\\Datasets\\dataset\\split_70_20_10\\valid'\n",
    "test_dir = r'C:\\Users\\xiaog\\Desktop\\Project\\Datasets\\dataset\\split_70_20_10\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42aa5a90-edcb-4dc5-bbd1-7454ce0a0fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 3748 images\n",
      "Valid set: 1071 images\n",
      "Test set: 533 images\n",
      "Train set - defect: 3321, no_defect: 427\n",
      "Valid set - defect: 942, no_defect: 129\n",
      "Test set - defect: 470, no_defect: 63\n"
     ]
    }
   ],
   "source": [
    "# get label\n",
    "def get_label_from_xml(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    objects = root.findall('object')\n",
    "\n",
    "    # if exist \"thermal_defect\", return 1\n",
    "    for obj in objects:\n",
    "        if obj.find('name').text == 'thermal_defect':\n",
    "            return \"1\"  \n",
    "\n",
    "    return \"0\" \n",
    "\n",
    "# count defects\n",
    "def count_defects_in_directory(data_dir):\n",
    "    with_defect = 0\n",
    "    without_defect = 0\n",
    "    \n",
    "    for root, _, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.xml'):\n",
    "                xml_path = os.path.join(root, file)\n",
    "                img_path = os.path.join(root.replace('annotations', 'images'), file.replace('.xml', '.jpg'))\n",
    "\n",
    "                if os.path.exists(img_path):  \n",
    "                    label = get_label_from_xml(xml_path)  \n",
    "                    if label == \"1\":\n",
    "                        with_defect += 1\n",
    "                    else:\n",
    "                        without_defect += 1\n",
    "    \n",
    "    return with_defect, without_defect\n",
    "\n",
    "def create_dataframe(data_dir):\n",
    "    data = []\n",
    "    \n",
    "    for root, _, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.xml'):\n",
    "                xml_path = os.path.join(root, file)\n",
    "                img_path = os.path.join(root.replace('annotations', 'images'), file.replace('.xml', '.jpg'))\n",
    "\n",
    "                if os.path.exists(img_path):  \n",
    "                    label = get_label_from_xml(xml_path) \n",
    "                    data.append([img_path, label])\n",
    "    \n",
    "    return pd.DataFrame(data, columns=['filepath', 'label'])\n",
    "\n",
    "train_df = create_dataframe(train_dir)\n",
    "valid_df = create_dataframe(valid_dir)\n",
    "test_df = create_dataframe(test_dir)\n",
    "\n",
    "print(f\"Train set: {len(train_df)} images\")\n",
    "print(f\"Valid set: {len(valid_df)} images\")\n",
    "print(f\"Test set: {len(test_df)} images\")\n",
    "\n",
    "train_with_defect, train_without_defect = count_defects_in_directory(train_dir)\n",
    "valid_with_defect, valid_without_defect = count_defects_in_directory(valid_dir)\n",
    "test_with_defect, test_without_defect = count_defects_in_directory(test_dir)\n",
    "\n",
    "print(f\"Train set - defect: {train_with_defect}, no_defect: {train_without_defect}\")\n",
    "print(f\"Valid set - defect: {valid_with_defect}, no_defect: {valid_without_defect}\")\n",
    "print(f\"Test set - defect: {test_with_defect}, no_defect: {test_without_defect}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e4801f0-48d0-4dcd-be22-0e58d905a3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3748 validated image filenames belonging to 2 classes.\n",
      "Found 1071 validated image filenames belonging to 2 classes.\n",
      "Found 533 validated image filenames belonging to 2 classes.\n",
      "Train generator samples: 3748\n",
      "Valid generator samples: 1071\n",
      "Test generator samples: 533\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  \n",
    "    rotation_range=30,  \n",
    "    width_shift_range=0.2,  \n",
    "    height_shift_range=0.2,  \n",
    "    shear_range=0.2, \n",
    "    zoom_range=0.2, \n",
    "    horizontal_flip=True \n",
    ")\n",
    "\n",
    "valid_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# train generator\n",
    "train_generator_70_20_10 = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\"  \n",
    ")\n",
    "\n",
    "# valid generator\n",
    "valid_generator_70_20_10 = valid_test_datagen.flow_from_dataframe(\n",
    "    dataframe=valid_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "# test generator\n",
    "test_generator_70_20_10 = valid_test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False  \n",
    ")\n",
    "\n",
    "print(f\"Train generator samples: {train_generator_70_20_10.samples}\")\n",
    "print(f\"Valid generator samples: {valid_generator_70_20_10.samples}\")\n",
    "print(f\"Test generator samples: {test_generator_70_20_10.samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "535f4296-7d5c-4aa0-9b1f-cb1978ae87c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 128, 128, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 128, 128, 32  128         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 128, 128, 32  896         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 128, 128, 32  2432        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 128, 128, 32  128         ['max_pooling2d[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 128, 128, 12  0           ['conv2d[0][0]',                 \n",
      "                                8)                                'conv2d_1[0][0]',               \n",
      "                                                                  'conv2d_2[0][0]',               \n",
      "                                                                  'conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0          ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 128)  0          ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 64, 64, 64)   8256        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 64, 64, 64)   73792       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 64, 64, 64)   204864      ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 64, 64, 64)   8256        ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 64, 64, 256)  0           ['conv2d_4[0][0]',               \n",
      "                                                                  'conv2d_5[0][0]',               \n",
      "                                                                  'conv2d_6[0][0]',               \n",
      "                                                                  'conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 256)  0          ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 32, 32, 256)  0          ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 32, 32, 128)  32896       ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 32, 32, 128)  295040      ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 32, 32, 128)  819328      ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 32, 32, 128)  32896       ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 32, 32, 512)  0           ['conv2d_8[0][0]',               \n",
      "                                                                  'conv2d_9[0][0]',               \n",
      "                                                                  'conv2d_10[0][0]',              \n",
      "                                                                  'conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 512)         0           ['concatenate_2[0][0]']          \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 4, 128)       0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 4, 1)         129         ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 4)            0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 4)            0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 4, 1)         0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 4, 128)       0           ['reshape[0][0]',                \n",
      "                                                                  'reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 128)         0           ['multiply[0][0]']               \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 2)            258         ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,479,299\n",
      "Trainable params: 1,479,299\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def inception_module(x, filters):\n",
    "    # 1x1 Conv\n",
    "    conv1x1 = Conv2D(filters, (1,1), padding='same', activation='relu')(x)\n",
    "    \n",
    "    # 3x3 Conv\n",
    "    conv3x3 = Conv2D(filters, (3,3), padding='same', activation='relu')(x)\n",
    "    \n",
    "    # 5x5 Conv\n",
    "    conv5x5 = Conv2D(filters, (5,5), padding='same', activation='relu')(x)\n",
    "    \n",
    "    pool = MaxPooling2D((3,3), strides=(1,1), padding='same')(x)\n",
    "    pool = Conv2D(filters, (1,1), padding='same', activation='relu')(pool)\n",
    "    \n",
    "    merged = concatenate([conv1x1, conv3x3, conv5x5, pool], axis=-1)\n",
    "    return merged\n",
    "\n",
    "def attention_block(inputs):\n",
    "    attention = Dense(1, activation='tanh')(inputs)    # (batch_size, seq_length, 1)\n",
    "    attention = Flatten()(attention)                   # (batch_size, seq_length)\n",
    "    attention = Activation('softmax')(attention)       # (batch_size, seq_length)\n",
    "    attention = Reshape((inputs.shape[1], 1))(attention)  # (batch_size, seq_length, 1)\n",
    "    \n",
    "    context = Multiply()([inputs, attention])          # (batch_size, seq_length, features)\n",
    "    return context\n",
    "\n",
    "\n",
    "def build_inception_attention_model(input_shape=(128, 128, 3), num_classes=2):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Inception module layers\n",
    "    x = inception_module(inputs, 32)\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    x = inception_module(x, 64)\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    x = inception_module(x, 128)\n",
    "    \n",
    "    # Attention block for feature selection\n",
    "    x = GlobalAveragePooling2D()(x)  # Global average pooling for feature reduction\n",
    "    x = Reshape((-1, 128))(x)  # Reshape for attention mechanism\n",
    "    x = attention_block(x)\n",
    "\n",
    "    # Final output layer\n",
    "    x = GlobalAveragePooling1D()(x)  # Pooling after attention block\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Create and return model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Build the modified model with Inception and Attention block\n",
    "inception_attention_model = build_inception_attention_model(input_shape=(128, 128, 3), num_classes=2)\n",
    "\n",
    "# Print the model summary\n",
    "inception_attention_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad4a945e-eeea-4cde-b3b5-bb4e0651e6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "def focal_loss(gamma=2., alpha=0.75):\n",
    "    \"\"\"\n",
    "    Focal Loss implementation for binary classification.\n",
    "\n",
    "    Parameters:\n",
    "        gamma (float): Focusing parameter. Default is 2.\n",
    "        alpha (float): Weighting factor for class imbalance. Default is 0.75 for better focusing on less frequent class.\n",
    "\n",
    "    Returns:\n",
    "        loss (function): Focal loss function.\n",
    "    \"\"\"\n",
    "\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        # Clip predictions to avoid log(0)\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1. - K.epsilon())\n",
    "\n",
    "        # Calculate cross entropy\n",
    "        cross_entropy = -y_true * K.log(y_pred)\n",
    "\n",
    "        # Calculate modulating factor (1 - p_t) ^ gamma\n",
    "        modulating_factor = K.pow(1 - y_pred, gamma)\n",
    "\n",
    "        # Calculate the focal loss\n",
    "        loss = alpha * modulating_factor * cross_entropy\n",
    "\n",
    "        return K.sum(loss, axis=-1)\n",
    "\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f5c10cf-3f35-4c0f-b2e0-01fdbd617dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "def compile_model(model, split_name=\"split_70_20_10\"):\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=1e-4),\n",
    "        loss=focal_loss(gamma=2., alpha=0.75),\n",
    "        metrics=[\n",
    "            'accuracy', \n",
    "            Precision(name='precision'), \n",
    "            Recall(name='recall'), \n",
    "            'AUC']\n",
    "    )\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),\n",
    "        ModelCheckpoint(\n",
    "            filepath=f'models/inception_attention_model_{split_name}.h5',\n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            mode='min',\n",
    "            verbose=1\n",
    "        ),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=1e-6)\n",
    "    ]\n",
    "\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df2a60bc-7bbb-46c1-89f8-bf889ab862cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0753 - accuracy: 0.8851 - precision: 0.8851 - recall: 0.8851 - auc: 0.8890\n",
      "Epoch 1: val_loss improved from inf to 0.07022, saving model to models\\inception_attention_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 106s 821ms/step - loss: 0.0753 - accuracy: 0.8851 - precision: 0.8851 - recall: 0.8851 - auc: 0.8890 - val_loss: 0.0702 - val_accuracy: 0.8797 - val_precision: 0.8797 - val_recall: 0.8797 - val_auc: 0.9088 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0682 - accuracy: 0.8859 - precision: 0.8859 - recall: 0.8859 - auc: 0.9187\n",
      "Epoch 2: val_loss improved from 0.07022 to 0.06785, saving model to models\\inception_attention_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 99s 844ms/step - loss: 0.0682 - accuracy: 0.8859 - precision: 0.8859 - recall: 0.8859 - auc: 0.9187 - val_loss: 0.0678 - val_accuracy: 0.8788 - val_precision: 0.8788 - val_recall: 0.8788 - val_auc: 0.9325 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0649 - accuracy: 0.8859 - precision: 0.8859 - recall: 0.8859 - auc: 0.9301\n",
      "Epoch 3: val_loss improved from 0.06785 to 0.06403, saving model to models\\inception_attention_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 98s 833ms/step - loss: 0.0649 - accuracy: 0.8859 - precision: 0.8859 - recall: 0.8859 - auc: 0.9301 - val_loss: 0.0640 - val_accuracy: 0.8807 - val_precision: 0.8807 - val_recall: 0.8807 - val_auc: 0.9376 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0619 - accuracy: 0.8859 - precision: 0.8859 - recall: 0.8859 - auc: 0.9385\n",
      "Epoch 4: val_loss improved from 0.06403 to 0.06206, saving model to models\\inception_attention_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 95s 813ms/step - loss: 0.0619 - accuracy: 0.8859 - precision: 0.8859 - recall: 0.8859 - auc: 0.9385 - val_loss: 0.0621 - val_accuracy: 0.8807 - val_precision: 0.8807 - val_recall: 0.8807 - val_auc: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0613 - accuracy: 0.8856 - precision: 0.8856 - recall: 0.8856 - auc: 0.9399\n",
      "Epoch 5: val_loss did not improve from 0.06206\n",
      "117/117 [==============================] - 97s 826ms/step - loss: 0.0613 - accuracy: 0.8856 - precision: 0.8856 - recall: 0.8856 - auc: 0.9399 - val_loss: 0.0628 - val_accuracy: 0.8778 - val_precision: 0.8778 - val_recall: 0.8778 - val_auc: 0.9405 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0601 - accuracy: 0.8862 - precision: 0.8862 - recall: 0.8862 - auc: 0.9417\n",
      "Epoch 6: val_loss improved from 0.06206 to 0.06150, saving model to models\\inception_attention_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 97s 829ms/step - loss: 0.0601 - accuracy: 0.8862 - precision: 0.8862 - recall: 0.8862 - auc: 0.9417 - val_loss: 0.0615 - val_accuracy: 0.8778 - val_precision: 0.8778 - val_recall: 0.8778 - val_auc: 0.9414 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 0.8870 - precision: 0.8870 - recall: 0.8870 - auc: 0.9420\n",
      "Epoch 7: val_loss improved from 0.06150 to 0.05860, saving model to models\\inception_attention_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 97s 827ms/step - loss: 0.0599 - accuracy: 0.8870 - precision: 0.8870 - recall: 0.8870 - auc: 0.9420 - val_loss: 0.0586 - val_accuracy: 0.8816 - val_precision: 0.8816 - val_recall: 0.8816 - val_auc: 0.9444 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0590 - accuracy: 0.8889 - precision: 0.8889 - recall: 0.8889 - auc: 0.9433\n",
      "Epoch 8: val_loss did not improve from 0.05860\n",
      "117/117 [==============================] - 99s 847ms/step - loss: 0.0590 - accuracy: 0.8889 - precision: 0.8889 - recall: 0.8889 - auc: 0.9433 - val_loss: 0.0589 - val_accuracy: 0.9006 - val_precision: 0.9006 - val_recall: 0.9006 - val_auc: 0.9454 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0580 - accuracy: 0.8907 - precision: 0.8907 - recall: 0.8907 - auc: 0.9456\n",
      "Epoch 9: val_loss improved from 0.05860 to 0.05850, saving model to models\\inception_attention_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 100s 853ms/step - loss: 0.0580 - accuracy: 0.8907 - precision: 0.8907 - recall: 0.8907 - auc: 0.9456 - val_loss: 0.0585 - val_accuracy: 0.8987 - val_precision: 0.8987 - val_recall: 0.8987 - val_auc: 0.9464 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0566 - accuracy: 0.8977 - precision: 0.8977 - recall: 0.8977 - auc: 0.9486\n",
      "Epoch 10: val_loss improved from 0.05850 to 0.05829, saving model to models\\inception_attention_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 99s 841ms/step - loss: 0.0566 - accuracy: 0.8977 - precision: 0.8977 - recall: 0.8977 - auc: 0.9486 - val_loss: 0.0583 - val_accuracy: 0.8996 - val_precision: 0.8996 - val_recall: 0.8996 - val_auc: 0.9473 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0566 - accuracy: 0.8988 - precision: 0.8988 - recall: 0.8988 - auc: 0.9484\n",
      "Epoch 11: val_loss did not improve from 0.05829\n",
      "117/117 [==============================] - 99s 847ms/step - loss: 0.0566 - accuracy: 0.8988 - precision: 0.8988 - recall: 0.8988 - auc: 0.9484 - val_loss: 0.0599 - val_accuracy: 0.9006 - val_precision: 0.9006 - val_recall: 0.9006 - val_auc: 0.9463 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0551 - accuracy: 0.9023 - precision: 0.9023 - recall: 0.9023 - auc: 0.9508\n",
      "Epoch 12: val_loss improved from 0.05829 to 0.05667, saving model to models\\inception_attention_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 99s 843ms/step - loss: 0.0551 - accuracy: 0.9023 - precision: 0.9023 - recall: 0.9023 - auc: 0.9508 - val_loss: 0.0567 - val_accuracy: 0.8968 - val_precision: 0.8968 - val_recall: 0.8968 - val_auc: 0.9495 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 0.9045 - precision: 0.9045 - recall: 0.9045 - auc: 0.9512\n",
      "Epoch 13: val_loss did not improve from 0.05667\n",
      "117/117 [==============================] - 95s 808ms/step - loss: 0.0547 - accuracy: 0.9045 - precision: 0.9045 - recall: 0.9045 - auc: 0.9512 - val_loss: 0.0573 - val_accuracy: 0.8996 - val_precision: 0.8996 - val_recall: 0.8996 - val_auc: 0.9478 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0535 - accuracy: 0.9050 - precision: 0.9050 - recall: 0.9050 - auc: 0.9530\n",
      "Epoch 14: val_loss improved from 0.05667 to 0.05566, saving model to models\\inception_attention_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 98s 834ms/step - loss: 0.0535 - accuracy: 0.9050 - precision: 0.9050 - recall: 0.9050 - auc: 0.9530 - val_loss: 0.0557 - val_accuracy: 0.8958 - val_precision: 0.8958 - val_recall: 0.8958 - val_auc: 0.9521 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0544 - accuracy: 0.9023 - precision: 0.9023 - recall: 0.9023 - auc: 0.9516\n",
      "Epoch 15: val_loss did not improve from 0.05566\n",
      "117/117 [==============================] - 101s 859ms/step - loss: 0.0544 - accuracy: 0.9023 - precision: 0.9023 - recall: 0.9023 - auc: 0.9516 - val_loss: 0.0560 - val_accuracy: 0.9006 - val_precision: 0.9006 - val_recall: 0.9006 - val_auc: 0.9534 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0542 - accuracy: 0.9053 - precision: 0.9053 - recall: 0.9053 - auc: 0.9513\n",
      "Epoch 16: val_loss did not improve from 0.05566\n",
      "117/117 [==============================] - 99s 844ms/step - loss: 0.0542 - accuracy: 0.9053 - precision: 0.9053 - recall: 0.9053 - auc: 0.9513 - val_loss: 0.0577 - val_accuracy: 0.8987 - val_precision: 0.8987 - val_recall: 0.8987 - val_auc: 0.9509 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0541 - accuracy: 0.9037 - precision: 0.9037 - recall: 0.9037 - auc: 0.9524\n",
      "Epoch 17: val_loss did not improve from 0.05566\n",
      "117/117 [==============================] - 97s 823ms/step - loss: 0.0541 - accuracy: 0.9037 - precision: 0.9037 - recall: 0.9037 - auc: 0.9524 - val_loss: 0.0560 - val_accuracy: 0.9006 - val_precision: 0.9006 - val_recall: 0.9006 - val_auc: 0.9546 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0530 - accuracy: 0.9055 - precision: 0.9055 - recall: 0.9055 - auc: 0.9543\n",
      "Epoch 18: val_loss did not improve from 0.05566\n",
      "117/117 [==============================] - 101s 858ms/step - loss: 0.0530 - accuracy: 0.9055 - precision: 0.9055 - recall: 0.9055 - auc: 0.9543 - val_loss: 0.0557 - val_accuracy: 0.9006 - val_precision: 0.9006 - val_recall: 0.9006 - val_auc: 0.9533 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0536 - accuracy: 0.9034 - precision: 0.9034 - recall: 0.9034 - auc: 0.9545\n",
      "Epoch 19: val_loss did not improve from 0.05566\n",
      "117/117 [==============================] - 95s 809ms/step - loss: 0.0536 - accuracy: 0.9034 - precision: 0.9034 - recall: 0.9034 - auc: 0.9545 - val_loss: 0.0558 - val_accuracy: 0.8949 - val_precision: 0.8949 - val_recall: 0.8949 - val_auc: 0.9528 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0524 - accuracy: 0.9050 - precision: 0.9050 - recall: 0.9050 - auc: 0.9560\n",
      "Epoch 20: val_loss improved from 0.05566 to 0.05498, saving model to models\\inception_attention_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 96s 821ms/step - loss: 0.0524 - accuracy: 0.9050 - precision: 0.9050 - recall: 0.9050 - auc: 0.9560 - val_loss: 0.0550 - val_accuracy: 0.9015 - val_precision: 0.9015 - val_recall: 0.9015 - val_auc: 0.9546 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0526 - accuracy: 0.9045 - precision: 0.9045 - recall: 0.9045 - auc: 0.9558\n",
      "Epoch 21: val_loss did not improve from 0.05498\n",
      "117/117 [==============================] - 96s 817ms/step - loss: 0.0526 - accuracy: 0.9045 - precision: 0.9045 - recall: 0.9045 - auc: 0.9558 - val_loss: 0.0573 - val_accuracy: 0.8864 - val_precision: 0.8864 - val_recall: 0.8864 - val_auc: 0.9518 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0530 - accuracy: 0.9026 - precision: 0.9026 - recall: 0.9026 - auc: 0.9554\n",
      "Epoch 22: val_loss did not improve from 0.05498\n",
      "117/117 [==============================] - 95s 811ms/step - loss: 0.0530 - accuracy: 0.9026 - precision: 0.9026 - recall: 0.9026 - auc: 0.9554 - val_loss: 0.0552 - val_accuracy: 0.8996 - val_precision: 0.8996 - val_recall: 0.8996 - val_auc: 0.9537 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0519 - accuracy: 0.9045 - precision: 0.9045 - recall: 0.9045 - auc: 0.9573\n",
      "Epoch 23: val_loss improved from 0.05498 to 0.05353, saving model to models\\inception_attention_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 82s 701ms/step - loss: 0.0519 - accuracy: 0.9045 - precision: 0.9045 - recall: 0.9045 - auc: 0.9573 - val_loss: 0.0535 - val_accuracy: 0.9025 - val_precision: 0.9025 - val_recall: 0.9025 - val_auc: 0.9575 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 0.9072 - precision: 0.9072 - recall: 0.9072 - auc: 0.9596\n",
      "Epoch 24: val_loss improved from 0.05353 to 0.05309, saving model to models\\inception_attention_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 98s 835ms/step - loss: 0.0506 - accuracy: 0.9072 - precision: 0.9072 - recall: 0.9072 - auc: 0.9596 - val_loss: 0.0531 - val_accuracy: 0.9006 - val_precision: 0.9006 - val_recall: 0.9006 - val_auc: 0.9596 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0512 - accuracy: 0.9031 - precision: 0.9031 - recall: 0.9031 - auc: 0.9586\n",
      "Epoch 25: val_loss improved from 0.05309 to 0.05280, saving model to models\\inception_attention_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 99s 839ms/step - loss: 0.0512 - accuracy: 0.9031 - precision: 0.9031 - recall: 0.9031 - auc: 0.9586 - val_loss: 0.0528 - val_accuracy: 0.9015 - val_precision: 0.9015 - val_recall: 0.9015 - val_auc: 0.9595 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0504 - accuracy: 0.9061 - precision: 0.9061 - recall: 0.9061 - auc: 0.9604\n",
      "Epoch 26: val_loss did not improve from 0.05280\n",
      "117/117 [==============================] - 98s 838ms/step - loss: 0.0504 - accuracy: 0.9061 - precision: 0.9061 - recall: 0.9061 - auc: 0.9604 - val_loss: 0.0567 - val_accuracy: 0.9006 - val_precision: 0.9006 - val_recall: 0.9006 - val_auc: 0.9512 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0512 - accuracy: 0.9037 - precision: 0.9037 - recall: 0.9037 - auc: 0.9585\n",
      "Epoch 27: val_loss improved from 0.05280 to 0.05198, saving model to models\\inception_attention_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 100s 853ms/step - loss: 0.0512 - accuracy: 0.9037 - precision: 0.9037 - recall: 0.9037 - auc: 0.9585 - val_loss: 0.0520 - val_accuracy: 0.9025 - val_precision: 0.9025 - val_recall: 0.9025 - val_auc: 0.9601 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0507 - accuracy: 0.9050 - precision: 0.9050 - recall: 0.9050 - auc: 0.9595\n",
      "Epoch 28: val_loss did not improve from 0.05198\n",
      "117/117 [==============================] - 105s 893ms/step - loss: 0.0507 - accuracy: 0.9050 - precision: 0.9050 - recall: 0.9050 - auc: 0.9595 - val_loss: 0.0561 - val_accuracy: 0.8826 - val_precision: 0.8826 - val_recall: 0.8826 - val_auc: 0.9512 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0507 - accuracy: 0.9074 - precision: 0.9074 - recall: 0.9074 - auc: 0.9597\n",
      "Epoch 29: val_loss did not improve from 0.05198\n",
      "117/117 [==============================] - 100s 851ms/step - loss: 0.0507 - accuracy: 0.9074 - precision: 0.9074 - recall: 0.9074 - auc: 0.9597 - val_loss: 0.0529 - val_accuracy: 0.8996 - val_precision: 0.8996 - val_recall: 0.8996 - val_auc: 0.9598 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0503 - accuracy: 0.9055 - precision: 0.9055 - recall: 0.9055 - auc: 0.9603\n",
      "Epoch 30: val_loss did not improve from 0.05198\n",
      "117/117 [==============================] - 101s 857ms/step - loss: 0.0503 - accuracy: 0.9055 - precision: 0.9055 - recall: 0.9055 - auc: 0.9603 - val_loss: 0.0522 - val_accuracy: 0.9025 - val_precision: 0.9025 - val_recall: 0.9025 - val_auc: 0.9599 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0498 - accuracy: 0.9042 - precision: 0.9042 - recall: 0.9042 - auc: 0.9619\n",
      "Epoch 31: val_loss did not improve from 0.05198\n",
      "117/117 [==============================] - 97s 824ms/step - loss: 0.0498 - accuracy: 0.9042 - precision: 0.9042 - recall: 0.9042 - auc: 0.9619 - val_loss: 0.0523 - val_accuracy: 0.8977 - val_precision: 0.8977 - val_recall: 0.8977 - val_auc: 0.9608 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0495 - accuracy: 0.9037 - precision: 0.9037 - recall: 0.9037 - auc: 0.9618\n",
      "Epoch 32: val_loss did not improve from 0.05198\n",
      "117/117 [==============================] - 85s 728ms/step - loss: 0.0495 - accuracy: 0.9037 - precision: 0.9037 - recall: 0.9037 - auc: 0.9618 - val_loss: 0.0532 - val_accuracy: 0.8987 - val_precision: 0.8987 - val_recall: 0.8987 - val_auc: 0.9591 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0499 - accuracy: 0.9050 - precision: 0.9050 - recall: 0.9050 - auc: 0.9618\n",
      "Epoch 33: val_loss improved from 0.05198 to 0.05111, saving model to models\\inception_attention_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 98s 832ms/step - loss: 0.0499 - accuracy: 0.9050 - precision: 0.9050 - recall: 0.9050 - auc: 0.9618 - val_loss: 0.0511 - val_accuracy: 0.9025 - val_precision: 0.9025 - val_recall: 0.9025 - val_auc: 0.9629 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0496 - accuracy: 0.9053 - precision: 0.9053 - recall: 0.9053 - auc: 0.9617\n",
      "Epoch 34: val_loss did not improve from 0.05111\n",
      "117/117 [==============================] - 99s 843ms/step - loss: 0.0496 - accuracy: 0.9053 - precision: 0.9053 - recall: 0.9053 - auc: 0.9617 - val_loss: 0.0519 - val_accuracy: 0.9015 - val_precision: 0.9015 - val_recall: 0.9015 - val_auc: 0.9609 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0494 - accuracy: 0.9034 - precision: 0.9034 - recall: 0.9034 - auc: 0.9626\n",
      "Epoch 35: val_loss improved from 0.05111 to 0.05062, saving model to models\\inception_attention_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 101s 863ms/step - loss: 0.0494 - accuracy: 0.9034 - precision: 0.9034 - recall: 0.9034 - auc: 0.9626 - val_loss: 0.0506 - val_accuracy: 0.9006 - val_precision: 0.9006 - val_recall: 0.9006 - val_auc: 0.9622 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0501 - accuracy: 0.9042 - precision: 0.9042 - recall: 0.9042 - auc: 0.9609\n",
      "Epoch 36: val_loss did not improve from 0.05062\n",
      "117/117 [==============================] - 101s 862ms/step - loss: 0.0501 - accuracy: 0.9042 - precision: 0.9042 - recall: 0.9042 - auc: 0.9609 - val_loss: 0.0537 - val_accuracy: 0.8987 - val_precision: 0.8987 - val_recall: 0.8987 - val_auc: 0.9584 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0490 - accuracy: 0.9058 - precision: 0.9058 - recall: 0.9058 - auc: 0.9631\n",
      "Epoch 37: val_loss did not improve from 0.05062\n",
      "117/117 [==============================] - 102s 871ms/step - loss: 0.0490 - accuracy: 0.9058 - precision: 0.9058 - recall: 0.9058 - auc: 0.9631 - val_loss: 0.0517 - val_accuracy: 0.8996 - val_precision: 0.8996 - val_recall: 0.8996 - val_auc: 0.9631 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0490 - accuracy: 0.9074 - precision: 0.9074 - recall: 0.9074 - auc: 0.9629\n",
      "Epoch 38: val_loss improved from 0.05062 to 0.04908, saving model to models\\inception_attention_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 101s 862ms/step - loss: 0.0490 - accuracy: 0.9074 - precision: 0.9074 - recall: 0.9074 - auc: 0.9629 - val_loss: 0.0491 - val_accuracy: 0.9015 - val_precision: 0.9015 - val_recall: 0.9015 - val_auc: 0.9650 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0494 - accuracy: 0.9064 - precision: 0.9064 - recall: 0.9064 - auc: 0.9624\n",
      "Epoch 39: val_loss did not improve from 0.04908\n",
      "117/117 [==============================] - 102s 869ms/step - loss: 0.0494 - accuracy: 0.9064 - precision: 0.9064 - recall: 0.9064 - auc: 0.9624 - val_loss: 0.0573 - val_accuracy: 0.8750 - val_precision: 0.8750 - val_recall: 0.8750 - val_auc: 0.9508 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0498 - accuracy: 0.9037 - precision: 0.9037 - recall: 0.9037 - auc: 0.9621\n",
      "Epoch 40: val_loss did not improve from 0.04908\n",
      "117/117 [==============================] - 101s 860ms/step - loss: 0.0498 - accuracy: 0.9037 - precision: 0.9037 - recall: 0.9037 - auc: 0.9621 - val_loss: 0.0501 - val_accuracy: 0.9025 - val_precision: 0.9025 - val_recall: 0.9025 - val_auc: 0.9634 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0493 - accuracy: 0.9045 - precision: 0.9045 - recall: 0.9045 - auc: 0.9626\n",
      "Epoch 41: val_loss improved from 0.04908 to 0.04903, saving model to models\\inception_attention_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 101s 856ms/step - loss: 0.0493 - accuracy: 0.9045 - precision: 0.9045 - recall: 0.9045 - auc: 0.9626 - val_loss: 0.0490 - val_accuracy: 0.9062 - val_precision: 0.9062 - val_recall: 0.9062 - val_auc: 0.9654 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0470 - accuracy: 0.9104 - precision: 0.9104 - recall: 0.9104 - auc: 0.9663\n",
      "Epoch 42: val_loss did not improve from 0.04903\n",
      "117/117 [==============================] - 99s 843ms/step - loss: 0.0470 - accuracy: 0.9104 - precision: 0.9104 - recall: 0.9104 - auc: 0.9663 - val_loss: 0.0501 - val_accuracy: 0.9025 - val_precision: 0.9025 - val_recall: 0.9025 - val_auc: 0.9655 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0488 - accuracy: 0.9047 - precision: 0.9047 - recall: 0.9047 - auc: 0.9635\n",
      "Epoch 43: val_loss improved from 0.04903 to 0.04891, saving model to models\\inception_attention_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 99s 844ms/step - loss: 0.0488 - accuracy: 0.9047 - precision: 0.9047 - recall: 0.9047 - auc: 0.9635 - val_loss: 0.0489 - val_accuracy: 0.9053 - val_precision: 0.9053 - val_recall: 0.9053 - val_auc: 0.9653 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0472 - accuracy: 0.9085 - precision: 0.9085 - recall: 0.9085 - auc: 0.9658\n",
      "Epoch 44: val_loss did not improve from 0.04891\n",
      "117/117 [==============================] - 99s 846ms/step - loss: 0.0472 - accuracy: 0.9085 - precision: 0.9085 - recall: 0.9085 - auc: 0.9658 - val_loss: 0.0524 - val_accuracy: 0.8987 - val_precision: 0.8987 - val_recall: 0.8987 - val_auc: 0.9602 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0484 - accuracy: 0.9074 - precision: 0.9074 - recall: 0.9074 - auc: 0.9636\n",
      "Epoch 45: val_loss did not improve from 0.04891\n",
      "117/117 [==============================] - 99s 848ms/step - loss: 0.0484 - accuracy: 0.9074 - precision: 0.9074 - recall: 0.9074 - auc: 0.9636 - val_loss: 0.0507 - val_accuracy: 0.9015 - val_precision: 0.9015 - val_recall: 0.9015 - val_auc: 0.9625 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0468 - accuracy: 0.9064 - precision: 0.9064 - recall: 0.9064 - auc: 0.9665\n",
      "Epoch 46: val_loss did not improve from 0.04891\n",
      "117/117 [==============================] - 104s 886ms/step - loss: 0.0468 - accuracy: 0.9064 - precision: 0.9064 - recall: 0.9064 - auc: 0.9665 - val_loss: 0.0489 - val_accuracy: 0.9006 - val_precision: 0.9006 - val_recall: 0.9006 - val_auc: 0.9648 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9050 - precision: 0.9050 - recall: 0.9050 - auc: 0.9632\n",
      "Epoch 47: val_loss did not improve from 0.04891\n",
      "117/117 [==============================] - 100s 852ms/step - loss: 0.0487 - accuracy: 0.9050 - precision: 0.9050 - recall: 0.9050 - auc: 0.9632 - val_loss: 0.0507 - val_accuracy: 0.9025 - val_precision: 0.9025 - val_recall: 0.9025 - val_auc: 0.9629 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0461 - accuracy: 0.9090 - precision: 0.9090 - recall: 0.9090 - auc: 0.9676\n",
      "Epoch 48: val_loss did not improve from 0.04891\n",
      "117/117 [==============================] - 100s 850ms/step - loss: 0.0461 - accuracy: 0.9090 - precision: 0.9090 - recall: 0.9090 - auc: 0.9676 - val_loss: 0.0491 - val_accuracy: 0.9081 - val_precision: 0.9081 - val_recall: 0.9081 - val_auc: 0.9678 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0460 - accuracy: 0.9088 - precision: 0.9088 - recall: 0.9088 - auc: 0.9681\n",
      "Epoch 49: val_loss did not improve from 0.04891\n",
      "117/117 [==============================] - 102s 869ms/step - loss: 0.0460 - accuracy: 0.9088 - precision: 0.9088 - recall: 0.9088 - auc: 0.9681 - val_loss: 0.0500 - val_accuracy: 0.9025 - val_precision: 0.9025 - val_recall: 0.9025 - val_auc: 0.9630 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0466 - accuracy: 0.9107 - precision: 0.9107 - recall: 0.9107 - auc: 0.9669\n",
      "Epoch 50: val_loss did not improve from 0.04891\n",
      "117/117 [==============================] - 103s 876ms/step - loss: 0.0466 - accuracy: 0.9107 - precision: 0.9107 - recall: 0.9107 - auc: 0.9669 - val_loss: 0.0497 - val_accuracy: 0.9072 - val_precision: 0.9072 - val_recall: 0.9072 - val_auc: 0.9661 - lr: 1.0000e-04\n",
      "Inception_attention_model_history for split_70_20_10 saved as models/inception_attention_model_history_split_70_20_10.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np \n",
    "\n",
    "def train_and_save_history(train_generator, valid_generator, split_name=\"split_70_20_10\", epochs=50, batch_size=32):\n",
    "    steps_per_epoch = train_generator.samples // batch_size\n",
    "    validation_steps = valid_generator.samples // batch_size\n",
    "\n",
    "   # compile model\n",
    "    model = build_inception_attention_model() \n",
    "\n",
    "    callbacks = compile_model(model, split_name)\n",
    "\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=valid_generator,\n",
    "        validation_steps=validation_steps,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    # save history\n",
    "    history_path = f\"models/inception_attention_model_history_{split_name}.pkl\"\n",
    "    with open(history_path, 'wb') as f:  \n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    print(f\"Inception_attention_model_history for {split_name} saved as {history_path}\")\n",
    "\n",
    "\n",
    "# train `split_80_10_10` and save history\n",
    "train_and_save_history(train_generator_70_20_10, valid_generator_70_20_10, split_name=\"split_70_20_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7dee953-e848-4a13-a5a1-23c999513643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 9s 406ms/step - loss: 0.0460 - accuracy: 0.9193 - precision: 0.9193 - recall: 0.9193 - auc: 0.9697\n",
      "Test Loss: 0.045958083122968674\n",
      "Test Accuracy: 0.9193245768547058\n",
      "Test Precision: 0.9193245768547058\n",
      "Test Recall: 0.9193245768547058\n",
      "Test AUC: 0.9696961045265198\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# load model and loss function\n",
    "model = load_model(\n",
    "    'models/inception_attention_model_split_70_20_10.h5',\n",
    "    custom_objects={'focal_loss_fixed': focal_loss(gamma=2., alpha=0.75)}  \n",
    ")\n",
    "\n",
    "# evaluation\n",
    "test_loss, test_accuracy, test_precision, test_recall, test_auc = model.evaluate(test_generator_70_20_10, verbose=1)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Precision: {test_precision}\")\n",
    "print(f\"Test Recall: {test_recall}\")\n",
    "print(f\"Test AUC: {test_auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1f6ca78-b520-475c-b55c-d55e11aa4a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 417ms/step\n",
      "1/1 [==============================] - 0s 476ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "Sensitivity (Recall): 0.9977272727272727\n",
      "Specificity: 0.3442622950819672\n",
      "Confusion matrix saved at: C:\\Users\\xiaog\\Desktop\\Project\\Datasets\\dataset\\Performance\\Inception_attention\\confusion_matrix_inception.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "save_dir = r\"C:\\Users\\xiaog\\Desktop\\Project\\Datasets\\dataset\\Performance\\Inception_attention\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "test_steps = test_generator_70_20_10.samples // test_generator_70_20_10.batch_size  \n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# get prediction result\n",
    "for _ in range(test_steps):\n",
    "    x, y = test_generator_70_20_10.next()\n",
    "    predictions = model.predict(x)\n",
    "    \n",
    "    # get true label\n",
    "    y_true.extend(np.argmax(y, axis=1)) \n",
    "    # get prediction label\n",
    "    y_pred.extend(np.argmax(predictions, axis=1))\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Calculate sensitivity (Recall) and specificity\n",
    "TP = cm[1, 1] \n",
    "TN = cm[0, 0]  \n",
    "FP = cm[0, 1]  \n",
    "FN = cm[1, 0]  \n",
    "\n",
    "sensitivity = TP / float(TP + FN)\n",
    "specificity = TN / float(TN + FP)\n",
    "\n",
    "print(f'Sensitivity (Recall): {sensitivity}')\n",
    "print(f'Specificity: {specificity}')\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Defect', 'Defect'], yticklabels=['No Defect', 'Defect'])\n",
    "plt.title('Confusion Matrix of Inception_Attention', fontsize=14)\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.ylabel('True', fontsize=12)\n",
    "\n",
    "# Save the confusion matrix plot\n",
    "confusion_matrix_path = os.path.join(save_dir, 'confusion_matrix_inception.png')\n",
    "plt.savefig(confusion_matrix_path, dpi=600, bbox_inches='tight')\n",
    "\n",
    "# Print the saved path\n",
    "print(f\"Confusion matrix saved at: {confusion_matrix_path}\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56cf4d0f-8621-4ebe-8cb9-251660ed0b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 770ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "F1 Score: 0.9633\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "test_steps = test_generator_70_20_10.samples // test_generator_70_20_10.batch_size\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for _ in range(test_steps):\n",
    "    x, y = test_generator_70_20_10.next()\n",
    "    predictions = model.predict(x)\n",
    "    y_true.extend(np.argmax(y, axis=1))              \n",
    "    y_pred.extend(np.argmax(predictions, axis=1))   \n",
    "\n",
    "f1 = f1_score(y_true, y_pred, average='binary') \n",
    "print(f'F1 Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c78d86-0d1e-4e69-93fd-8069a90f121b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea0767b-5839-45b0-9304-266aff97e990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed2aa8d-f9be-4887-bd19-1a1ed7323811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15110aa8-8f01-47e0-8147-333b4663f977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c82544-6b4d-48d5-8bba-7998301e5f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003dae7e-c391-40c0-beb0-fa1c5bfdc725",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
