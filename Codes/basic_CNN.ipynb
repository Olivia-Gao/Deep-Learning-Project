{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bccfe543-1f41-436d-965e-82ed34cca62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# data path\n",
    "train_dir = r'C:\\Users\\xiaog\\Desktop\\Project\\Datasets\\dataset\\split_70_20_10\\train'\n",
    "valid_dir = r'C:\\Users\\xiaog\\Desktop\\Project\\Datasets\\dataset\\split_70_20_10\\valid'\n",
    "test_dir = r'C:\\Users\\xiaog\\Desktop\\Project\\Datasets\\dataset\\split_70_20_10\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5f3c5f1-8add-4907-bd86-29990d9e02e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 3748 images\n",
      "Valid set: 1071 images\n",
      "Test set: 533 images\n",
      "Train set - defect: 3321, no_defect: 427\n",
      "Valid set - defect: 942, no_defect: 129\n",
      "Test set - defect: 470, no_defect: 63\n"
     ]
    }
   ],
   "source": [
    "# get label\n",
    "def get_label_from_xml(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    objects = root.findall('object')\n",
    "\n",
    "    # if exist \"thermal_defect\", return 1\n",
    "    for obj in objects:\n",
    "        if obj.find('name').text == 'thermal_defect':\n",
    "            return \"1\"  \n",
    "\n",
    "    return \"0\" \n",
    "\n",
    "# count defects\n",
    "def count_defects_in_directory(data_dir):\n",
    "    with_defect = 0\n",
    "    without_defect = 0\n",
    "    \n",
    "    for root, _, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.xml'):\n",
    "                xml_path = os.path.join(root, file)\n",
    "                img_path = os.path.join(root.replace('annotations', 'images'), file.replace('.xml', '.jpg'))\n",
    "\n",
    "                if os.path.exists(img_path):  \n",
    "                    label = get_label_from_xml(xml_path)  \n",
    "                    if label == \"1\":\n",
    "                        with_defect += 1\n",
    "                    else:\n",
    "                        without_defect += 1\n",
    "    \n",
    "    return with_defect, without_defect\n",
    "\n",
    "def create_dataframe(data_dir):\n",
    "    data = []\n",
    "    \n",
    "    for root, _, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.xml'):\n",
    "                xml_path = os.path.join(root, file)\n",
    "                img_path = os.path.join(root.replace('annotations', 'images'), file.replace('.xml', '.jpg'))\n",
    "\n",
    "                if os.path.exists(img_path):  \n",
    "                    label = get_label_from_xml(xml_path) \n",
    "                    data.append([img_path, label])\n",
    "    \n",
    "    return pd.DataFrame(data, columns=['filepath', 'label'])\n",
    "\n",
    "train_df = create_dataframe(train_dir)\n",
    "valid_df = create_dataframe(valid_dir)\n",
    "test_df = create_dataframe(test_dir)\n",
    "\n",
    "print(f\"Train set: {len(train_df)} images\")\n",
    "print(f\"Valid set: {len(valid_df)} images\")\n",
    "print(f\"Test set: {len(test_df)} images\")\n",
    "\n",
    "train_with_defect, train_without_defect = count_defects_in_directory(train_dir)\n",
    "valid_with_defect, valid_without_defect = count_defects_in_directory(valid_dir)\n",
    "test_with_defect, test_without_defect = count_defects_in_directory(test_dir)\n",
    "\n",
    "print(f\"Train set - defect: {train_with_defect}, no_defect: {train_without_defect}\")\n",
    "print(f\"Valid set - defect: {valid_with_defect}, no_defect: {valid_without_defect}\")\n",
    "print(f\"Test set - defect: {test_with_defect}, no_defect: {test_without_defect}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "653db2a1-7e52-4536-bd92-20260ff029d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3748 validated image filenames belonging to 2 classes.\n",
      "Found 1071 validated image filenames belonging to 2 classes.\n",
      "Found 533 validated image filenames belonging to 2 classes.\n",
      "Train generator samples: 3748\n",
      "Valid generator samples: 1071\n",
      "Test generator samples: 533\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  \n",
    "    rotation_range=30,  \n",
    "    width_shift_range=0.2,  \n",
    "    height_shift_range=0.2,  \n",
    "    shear_range=0.2, \n",
    "    zoom_range=0.2, \n",
    "    horizontal_flip=True \n",
    ")\n",
    "\n",
    "valid_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# train generator\n",
    "train_generator_70_20_10 = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\"  \n",
    ")\n",
    "\n",
    "# valid generator\n",
    "valid_generator_70_20_10 = valid_test_datagen.flow_from_dataframe(\n",
    "    dataframe=valid_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "# test generator\n",
    "test_generator_70_20_10 = valid_test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False  \n",
    ")\n",
    "\n",
    "print(f\"Train generator samples: {train_generator_70_20_10.samples}\")\n",
    "print(f\"Valid generator samples: {valid_generator_70_20_10.samples}\")\n",
    "print(f\"Test generator samples: {test_generator_70_20_10.samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d67bde26-6071-4b34-963a-608db2a898ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 128, 128, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 64, 64, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 65536)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 131074    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 131,522\n",
      "Trainable params: 131,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def simple_cnn_model(input_shape=(128, 128, 3), num_classes=2):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "model = simple_cnn_model(input_shape=(128, 128, 3), num_classes=2)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a162f83-06a8-4cf2-bac1-baa84b97a452",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "def focal_loss(gamma=2., alpha=0.75):\n",
    "    \"\"\"\n",
    "    Focal Loss implementation for binary classification.\n",
    "\n",
    "    Parameters:\n",
    "        gamma (float): Focusing parameter. Default is 2.\n",
    "        alpha (float): Weighting factor for class imbalance. Default is 0.75 for better focusing on less frequent class.\n",
    "\n",
    "    Returns:\n",
    "        loss (function): Focal loss function.\n",
    "    \"\"\"\n",
    "\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        # Clip predictions to avoid log(0)\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1. - K.epsilon())\n",
    "\n",
    "        # Calculate cross entropy\n",
    "        cross_entropy = -y_true * K.log(y_pred)\n",
    "\n",
    "        # Calculate modulating factor (1 - p_t) ^ gamma\n",
    "        modulating_factor = K.pow(1 - y_pred, gamma)\n",
    "\n",
    "        # Calculate the focal loss\n",
    "        loss = alpha * modulating_factor * cross_entropy\n",
    "\n",
    "        return K.sum(loss, axis=-1)\n",
    "\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e747dcf6-f816-40de-a043-163407ab971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "def compile_model(model, split_name=\"split_70_20_10\"):\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=1e-4),\n",
    "        loss=focal_loss(gamma=2., alpha=0.75),\n",
    "        metrics=[\n",
    "            'accuracy', \n",
    "            Precision(name='precision'), \n",
    "            Recall(name='recall'), \n",
    "            'AUC']\n",
    "    )\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),\n",
    "        ModelCheckpoint(\n",
    "            filepath=f'models/cnn_model_{split_name}.h5',\n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            mode='min',\n",
    "            verbose=1\n",
    "        ),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=1e-6)\n",
    "    ]\n",
    "\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85226b4c-5a8a-4f19-a2ee-a02152069172",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0797 - accuracy: 0.8724 - precision: 0.8724 - recall: 0.8724 - auc: 0.9008\n",
      "Epoch 1: val_loss improved from inf to 0.08501, saving model to models\\cnn_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 84s 676ms/step - loss: 0.0797 - accuracy: 0.8724 - precision: 0.8724 - recall: 0.8724 - auc: 0.9008 - val_loss: 0.0850 - val_accuracy: 0.8381 - val_precision: 0.8381 - val_recall: 0.8381 - val_auc: 0.8979 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 0.8829 - precision: 0.8829 - recall: 0.8829 - auc: 0.9104\n",
      "Epoch 2: val_loss improved from 0.08501 to 0.07060, saving model to models\\cnn_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 91s 778ms/step - loss: 0.0729 - accuracy: 0.8829 - precision: 0.8829 - recall: 0.8829 - auc: 0.9104 - val_loss: 0.0706 - val_accuracy: 0.8778 - val_precision: 0.8778 - val_recall: 0.8778 - val_auc: 0.9155 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0723 - accuracy: 0.8819 - precision: 0.8819 - recall: 0.8819 - auc: 0.9102\n",
      "Epoch 3: val_loss improved from 0.07060 to 0.06747, saving model to models\\cnn_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 90s 772ms/step - loss: 0.0723 - accuracy: 0.8819 - precision: 0.8819 - recall: 0.8819 - auc: 0.9102 - val_loss: 0.0675 - val_accuracy: 0.8759 - val_precision: 0.8759 - val_recall: 0.8759 - val_auc: 0.9231 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.8859 - precision: 0.8859 - recall: 0.8859 - auc: 0.9271\n",
      "Epoch 4: val_loss did not improve from 0.06747\n",
      "117/117 [==============================] - 93s 796ms/step - loss: 0.0667 - accuracy: 0.8859 - precision: 0.8859 - recall: 0.8859 - auc: 0.9271 - val_loss: 0.0702 - val_accuracy: 0.8778 - val_precision: 0.8778 - val_recall: 0.8778 - val_auc: 0.9255 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0670 - accuracy: 0.8856 - precision: 0.8856 - recall: 0.8856 - auc: 0.9217\n",
      "Epoch 5: val_loss did not improve from 0.06747\n",
      "117/117 [==============================] - 95s 810ms/step - loss: 0.0670 - accuracy: 0.8856 - precision: 0.8856 - recall: 0.8856 - auc: 0.9217 - val_loss: 0.0689 - val_accuracy: 0.8807 - val_precision: 0.8807 - val_recall: 0.8807 - val_auc: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0652 - accuracy: 0.8856 - precision: 0.8856 - recall: 0.8856 - auc: 0.9288\n",
      "Epoch 6: val_loss did not improve from 0.06747\n",
      "117/117 [==============================] - 92s 783ms/step - loss: 0.0652 - accuracy: 0.8856 - precision: 0.8856 - recall: 0.8856 - auc: 0.9288 - val_loss: 0.0725 - val_accuracy: 0.8523 - val_precision: 0.8523 - val_recall: 0.8523 - val_auc: 0.9209 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0637 - accuracy: 0.8886 - precision: 0.8886 - recall: 0.8886 - auc: 0.9302\n",
      "Epoch 7: val_loss improved from 0.06747 to 0.06520, saving model to models\\cnn_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 97s 826ms/step - loss: 0.0637 - accuracy: 0.8886 - precision: 0.8886 - recall: 0.8886 - auc: 0.9302 - val_loss: 0.0652 - val_accuracy: 0.8864 - val_precision: 0.8864 - val_recall: 0.8864 - val_auc: 0.9361 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0639 - accuracy: 0.8881 - precision: 0.8881 - recall: 0.8881 - auc: 0.9329\n",
      "Epoch 8: val_loss improved from 0.06520 to 0.06208, saving model to models\\cnn_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 90s 771ms/step - loss: 0.0639 - accuracy: 0.8881 - precision: 0.8881 - recall: 0.8881 - auc: 0.9329 - val_loss: 0.0621 - val_accuracy: 0.8854 - val_precision: 0.8854 - val_recall: 0.8854 - val_auc: 0.9367 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0612 - accuracy: 0.8929 - precision: 0.8929 - recall: 0.8929 - auc: 0.9374\n",
      "Epoch 9: val_loss improved from 0.06208 to 0.06125, saving model to models\\cnn_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 93s 790ms/step - loss: 0.0612 - accuracy: 0.8929 - precision: 0.8929 - recall: 0.8929 - auc: 0.9374 - val_loss: 0.0612 - val_accuracy: 0.8864 - val_precision: 0.8864 - val_recall: 0.8864 - val_auc: 0.9386 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0621 - accuracy: 0.8937 - precision: 0.8937 - recall: 0.8937 - auc: 0.9352\n",
      "Epoch 10: val_loss improved from 0.06125 to 0.06054, saving model to models\\cnn_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 99s 845ms/step - loss: 0.0621 - accuracy: 0.8937 - precision: 0.8937 - recall: 0.8937 - auc: 0.9352 - val_loss: 0.0605 - val_accuracy: 0.8996 - val_precision: 0.8996 - val_recall: 0.8996 - val_auc: 0.9410 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0627 - accuracy: 0.8891 - precision: 0.8891 - recall: 0.8891 - auc: 0.9356\n",
      "Epoch 11: val_loss improved from 0.06054 to 0.05839, saving model to models\\cnn_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 94s 807ms/step - loss: 0.0627 - accuracy: 0.8891 - precision: 0.8891 - recall: 0.8891 - auc: 0.9356 - val_loss: 0.0584 - val_accuracy: 0.9006 - val_precision: 0.9006 - val_recall: 0.9006 - val_auc: 0.9444 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0600 - accuracy: 0.8937 - precision: 0.8937 - recall: 0.8937 - auc: 0.9416\n",
      "Epoch 12: val_loss did not improve from 0.05839\n",
      "117/117 [==============================] - 100s 858ms/step - loss: 0.0600 - accuracy: 0.8937 - precision: 0.8937 - recall: 0.8937 - auc: 0.9416 - val_loss: 0.0616 - val_accuracy: 0.8854 - val_precision: 0.8854 - val_recall: 0.8854 - val_auc: 0.9411 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0586 - accuracy: 0.8980 - precision: 0.8980 - recall: 0.8980 - auc: 0.9434\n",
      "Epoch 13: val_loss did not improve from 0.05839\n",
      "117/117 [==============================] - 94s 802ms/step - loss: 0.0586 - accuracy: 0.8980 - precision: 0.8980 - recall: 0.8980 - auc: 0.9434 - val_loss: 0.0604 - val_accuracy: 0.8949 - val_precision: 0.8949 - val_recall: 0.8949 - val_auc: 0.9418 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 0.8961 - precision: 0.8961 - recall: 0.8961 - auc: 0.9417\n",
      "Epoch 14: val_loss did not improve from 0.05839\n",
      "117/117 [==============================] - 93s 791ms/step - loss: 0.0598 - accuracy: 0.8961 - precision: 0.8961 - recall: 0.8961 - auc: 0.9417 - val_loss: 0.0591 - val_accuracy: 0.8968 - val_precision: 0.8968 - val_recall: 0.8968 - val_auc: 0.9423 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 0.8956 - precision: 0.8956 - recall: 0.8956 - auc: 0.9427\n",
      "Epoch 15: val_loss did not improve from 0.05839\n",
      "117/117 [==============================] - 95s 808ms/step - loss: 0.0598 - accuracy: 0.8956 - precision: 0.8956 - recall: 0.8956 - auc: 0.9427 - val_loss: 0.0604 - val_accuracy: 0.8864 - val_precision: 0.8864 - val_recall: 0.8864 - val_auc: 0.9444 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 0.8956 - precision: 0.8956 - recall: 0.8956 - auc: 0.9453\n",
      "Epoch 16: val_loss improved from 0.05839 to 0.05833, saving model to models\\cnn_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 101s 864ms/step - loss: 0.0581 - accuracy: 0.8956 - precision: 0.8956 - recall: 0.8956 - auc: 0.9453 - val_loss: 0.0583 - val_accuracy: 0.8958 - val_precision: 0.8958 - val_recall: 0.8958 - val_auc: 0.9451 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0585 - accuracy: 0.8959 - precision: 0.8959 - recall: 0.8959 - auc: 0.9457\n",
      "Epoch 17: val_loss did not improve from 0.05833\n",
      "117/117 [==============================] - 94s 801ms/step - loss: 0.0585 - accuracy: 0.8959 - precision: 0.8959 - recall: 0.8959 - auc: 0.9457 - val_loss: 0.0588 - val_accuracy: 0.8911 - val_precision: 0.8911 - val_recall: 0.8911 - val_auc: 0.9434 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 0.8988 - precision: 0.8988 - recall: 0.8988 - auc: 0.9444\n",
      "Epoch 18: val_loss did not improve from 0.05833\n",
      "117/117 [==============================] - 100s 856ms/step - loss: 0.0583 - accuracy: 0.8988 - precision: 0.8988 - recall: 0.8988 - auc: 0.9444 - val_loss: 0.0593 - val_accuracy: 0.8939 - val_precision: 0.8939 - val_recall: 0.8939 - val_auc: 0.9442 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0578 - accuracy: 0.9015 - precision: 0.9015 - recall: 0.9015 - auc: 0.9461\n",
      "Epoch 19: val_loss did not improve from 0.05833\n",
      "117/117 [==============================] - 98s 835ms/step - loss: 0.0578 - accuracy: 0.9015 - precision: 0.9015 - recall: 0.9015 - auc: 0.9461 - val_loss: 0.0601 - val_accuracy: 0.8911 - val_precision: 0.8911 - val_recall: 0.8911 - val_auc: 0.9456 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0590 - accuracy: 0.8961 - precision: 0.8961 - recall: 0.8961 - auc: 0.9443\n",
      "Epoch 20: val_loss did not improve from 0.05833\n",
      "117/117 [==============================] - 96s 816ms/step - loss: 0.0590 - accuracy: 0.8961 - precision: 0.8961 - recall: 0.8961 - auc: 0.9443 - val_loss: 0.0596 - val_accuracy: 0.9015 - val_precision: 0.9015 - val_recall: 0.9015 - val_auc: 0.9474 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0567 - accuracy: 0.9004 - precision: 0.9004 - recall: 0.9004 - auc: 0.9484\n",
      "Epoch 21: val_loss improved from 0.05833 to 0.05814, saving model to models\\cnn_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 104s 888ms/step - loss: 0.0567 - accuracy: 0.9004 - precision: 0.9004 - recall: 0.9004 - auc: 0.9484 - val_loss: 0.0581 - val_accuracy: 0.8987 - val_precision: 0.8987 - val_recall: 0.8987 - val_auc: 0.9481 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0565 - accuracy: 0.9023 - precision: 0.9023 - recall: 0.9023 - auc: 0.9485\n",
      "Epoch 22: val_loss did not improve from 0.05814\n",
      "117/117 [==============================] - 96s 818ms/step - loss: 0.0565 - accuracy: 0.9023 - precision: 0.9023 - recall: 0.9023 - auc: 0.9485 - val_loss: 0.0583 - val_accuracy: 0.8968 - val_precision: 0.8968 - val_recall: 0.8968 - val_auc: 0.9468 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0575 - accuracy: 0.9007 - precision: 0.9007 - recall: 0.9007 - auc: 0.9480\n",
      "Epoch 23: val_loss improved from 0.05814 to 0.05791, saving model to models\\cnn_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 94s 804ms/step - loss: 0.0575 - accuracy: 0.9007 - precision: 0.9007 - recall: 0.9007 - auc: 0.9480 - val_loss: 0.0579 - val_accuracy: 0.8958 - val_precision: 0.8958 - val_recall: 0.8958 - val_auc: 0.9479 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0559 - accuracy: 0.9015 - precision: 0.9015 - recall: 0.9015 - auc: 0.9503\n",
      "Epoch 24: val_loss improved from 0.05791 to 0.05780, saving model to models\\cnn_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 92s 790ms/step - loss: 0.0559 - accuracy: 0.9015 - precision: 0.9015 - recall: 0.9015 - auc: 0.9503 - val_loss: 0.0578 - val_accuracy: 0.8977 - val_precision: 0.8977 - val_recall: 0.8977 - val_auc: 0.9465 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0562 - accuracy: 0.8988 - precision: 0.8988 - recall: 0.8988 - auc: 0.9508\n",
      "Epoch 25: val_loss did not improve from 0.05780\n",
      "117/117 [==============================] - 94s 801ms/step - loss: 0.0562 - accuracy: 0.8988 - precision: 0.8988 - recall: 0.8988 - auc: 0.9508 - val_loss: 0.0720 - val_accuracy: 0.8826 - val_precision: 0.8826 - val_recall: 0.8826 - val_auc: 0.9362 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0563 - accuracy: 0.9002 - precision: 0.9002 - recall: 0.9002 - auc: 0.9496\n",
      "Epoch 26: val_loss improved from 0.05780 to 0.05768, saving model to models\\cnn_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 100s 853ms/step - loss: 0.0563 - accuracy: 0.9002 - precision: 0.9002 - recall: 0.9002 - auc: 0.9496 - val_loss: 0.0577 - val_accuracy: 0.8977 - val_precision: 0.8977 - val_recall: 0.8977 - val_auc: 0.9469 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0543 - accuracy: 0.9026 - precision: 0.9026 - recall: 0.9026 - auc: 0.9534\n",
      "Epoch 27: val_loss did not improve from 0.05768\n",
      "117/117 [==============================] - 104s 888ms/step - loss: 0.0543 - accuracy: 0.9026 - precision: 0.9026 - recall: 0.9026 - auc: 0.9534 - val_loss: 0.0607 - val_accuracy: 0.8977 - val_precision: 0.8977 - val_recall: 0.8977 - val_auc: 0.9469 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0546 - accuracy: 0.9015 - precision: 0.9015 - recall: 0.9015 - auc: 0.9537\n",
      "Epoch 28: val_loss improved from 0.05768 to 0.05731, saving model to models\\cnn_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 100s 855ms/step - loss: 0.0546 - accuracy: 0.9015 - precision: 0.9015 - recall: 0.9015 - auc: 0.9537 - val_loss: 0.0573 - val_accuracy: 0.8987 - val_precision: 0.8987 - val_recall: 0.8987 - val_auc: 0.9496 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0564 - accuracy: 0.9015 - precision: 0.9015 - recall: 0.9015 - auc: 0.9502\n",
      "Epoch 29: val_loss did not improve from 0.05731\n",
      "117/117 [==============================] - 92s 783ms/step - loss: 0.0564 - accuracy: 0.9015 - precision: 0.9015 - recall: 0.9015 - auc: 0.9502 - val_loss: 0.0640 - val_accuracy: 0.8977 - val_precision: 0.8977 - val_recall: 0.8977 - val_auc: 0.9475 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0557 - accuracy: 0.9029 - precision: 0.9029 - recall: 0.9029 - auc: 0.9512\n",
      "Epoch 30: val_loss did not improve from 0.05731\n",
      "117/117 [==============================] - 92s 787ms/step - loss: 0.0557 - accuracy: 0.9029 - precision: 0.9029 - recall: 0.9029 - auc: 0.9512 - val_loss: 0.0582 - val_accuracy: 0.8996 - val_precision: 0.8996 - val_recall: 0.8996 - val_auc: 0.9451 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0529 - accuracy: 0.9055 - precision: 0.9055 - recall: 0.9055 - auc: 0.9558\n",
      "Epoch 31: val_loss did not improve from 0.05731\n",
      "117/117 [==============================] - 96s 824ms/step - loss: 0.0529 - accuracy: 0.9055 - precision: 0.9055 - recall: 0.9055 - auc: 0.9558 - val_loss: 0.0602 - val_accuracy: 0.8987 - val_precision: 0.8987 - val_recall: 0.8987 - val_auc: 0.9445 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0527 - accuracy: 0.9031 - precision: 0.9031 - recall: 0.9031 - auc: 0.9570\n",
      "Epoch 32: val_loss did not improve from 0.05731\n",
      "117/117 [==============================] - 100s 853ms/step - loss: 0.0527 - accuracy: 0.9031 - precision: 0.9031 - recall: 0.9031 - auc: 0.9570 - val_loss: 0.0648 - val_accuracy: 0.8968 - val_precision: 0.8968 - val_recall: 0.8968 - val_auc: 0.9449 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0555 - accuracy: 0.9010 - precision: 0.9010 - recall: 0.9010 - auc: 0.9516\n",
      "Epoch 33: val_loss did not improve from 0.05731\n",
      "117/117 [==============================] - 100s 850ms/step - loss: 0.0555 - accuracy: 0.9010 - precision: 0.9010 - recall: 0.9010 - auc: 0.9516 - val_loss: 0.0617 - val_accuracy: 0.8996 - val_precision: 0.8996 - val_recall: 0.8996 - val_auc: 0.9480 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 0.9012 - precision: 0.9012 - recall: 0.9012 - auc: 0.9531\n",
      "Epoch 34: val_loss did not improve from 0.05731\n",
      "117/117 [==============================] - 98s 837ms/step - loss: 0.0547 - accuracy: 0.9012 - precision: 0.9012 - recall: 0.9012 - auc: 0.9531 - val_loss: 0.0575 - val_accuracy: 0.8977 - val_precision: 0.8977 - val_recall: 0.8977 - val_auc: 0.9479 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0548 - accuracy: 0.9023 - precision: 0.9023 - recall: 0.9023 - auc: 0.9535\n",
      "Epoch 35: val_loss improved from 0.05731 to 0.05686, saving model to models\\cnn_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 106s 902ms/step - loss: 0.0548 - accuracy: 0.9023 - precision: 0.9023 - recall: 0.9023 - auc: 0.9535 - val_loss: 0.0569 - val_accuracy: 0.9015 - val_precision: 0.9015 - val_recall: 0.9015 - val_auc: 0.9483 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0524 - accuracy: 0.9026 - precision: 0.9026 - recall: 0.9026 - auc: 0.9565\n",
      "Epoch 36: val_loss did not improve from 0.05686\n",
      "117/117 [==============================] - 99s 849ms/step - loss: 0.0524 - accuracy: 0.9026 - precision: 0.9026 - recall: 0.9026 - auc: 0.9565 - val_loss: 0.0578 - val_accuracy: 0.9034 - val_precision: 0.9034 - val_recall: 0.9034 - val_auc: 0.9499 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0542 - accuracy: 0.8991 - precision: 0.8991 - recall: 0.8991 - auc: 0.9553\n",
      "Epoch 37: val_loss did not improve from 0.05686\n",
      "117/117 [==============================] - 99s 847ms/step - loss: 0.0542 - accuracy: 0.8991 - precision: 0.8991 - recall: 0.8991 - auc: 0.9553 - val_loss: 0.0569 - val_accuracy: 0.9006 - val_precision: 0.9006 - val_recall: 0.9006 - val_auc: 0.9488 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0536 - accuracy: 0.9012 - precision: 0.9012 - recall: 0.9012 - auc: 0.9551\n",
      "Epoch 38: val_loss did not improve from 0.05686\n",
      "117/117 [==============================] - 100s 857ms/step - loss: 0.0536 - accuracy: 0.9012 - precision: 0.9012 - recall: 0.9012 - auc: 0.9551 - val_loss: 0.0571 - val_accuracy: 0.9015 - val_precision: 0.9015 - val_recall: 0.9015 - val_auc: 0.9478 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0542 - accuracy: 0.9026 - precision: 0.9026 - recall: 0.9026 - auc: 0.9547\n",
      "Epoch 39: val_loss did not improve from 0.05686\n",
      "117/117 [==============================] - 100s 856ms/step - loss: 0.0542 - accuracy: 0.9026 - precision: 0.9026 - recall: 0.9026 - auc: 0.9547 - val_loss: 0.0569 - val_accuracy: 0.9006 - val_precision: 0.9006 - val_recall: 0.9006 - val_auc: 0.9475 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0530 - accuracy: 0.9039 - precision: 0.9039 - recall: 0.9039 - auc: 0.9559\n",
      "Epoch 40: val_loss did not improve from 0.05686\n",
      "117/117 [==============================] - 99s 844ms/step - loss: 0.0530 - accuracy: 0.9039 - precision: 0.9039 - recall: 0.9039 - auc: 0.9559 - val_loss: 0.0582 - val_accuracy: 0.8987 - val_precision: 0.8987 - val_recall: 0.8987 - val_auc: 0.9485 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 0.9037 - precision: 0.9037 - recall: 0.9037 - auc: 0.9558\n",
      "Epoch 41: val_loss did not improve from 0.05686\n",
      "117/117 [==============================] - 102s 871ms/step - loss: 0.0537 - accuracy: 0.9037 - precision: 0.9037 - recall: 0.9037 - auc: 0.9558 - val_loss: 0.0622 - val_accuracy: 0.8977 - val_precision: 0.8977 - val_recall: 0.8977 - val_auc: 0.9460 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0533 - accuracy: 0.8996 - precision: 0.8996 - recall: 0.8996 - auc: 0.9552\n",
      "Epoch 42: val_loss did not improve from 0.05686\n",
      "117/117 [==============================] - 105s 898ms/step - loss: 0.0533 - accuracy: 0.8996 - precision: 0.8996 - recall: 0.8996 - auc: 0.9552 - val_loss: 0.0571 - val_accuracy: 0.9015 - val_precision: 0.9015 - val_recall: 0.9015 - val_auc: 0.9492 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0534 - accuracy: 0.9039 - precision: 0.9039 - recall: 0.9039 - auc: 0.9551\n",
      "Epoch 43: val_loss did not improve from 0.05686\n",
      "117/117 [==============================] - 100s 854ms/step - loss: 0.0534 - accuracy: 0.9039 - precision: 0.9039 - recall: 0.9039 - auc: 0.9551 - val_loss: 0.0572 - val_accuracy: 0.9006 - val_precision: 0.9006 - val_recall: 0.9006 - val_auc: 0.9489 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0531 - accuracy: 0.9045 - precision: 0.9045 - recall: 0.9045 - auc: 0.9555\n",
      "Epoch 44: val_loss did not improve from 0.05686\n",
      "117/117 [==============================] - 101s 866ms/step - loss: 0.0531 - accuracy: 0.9045 - precision: 0.9045 - recall: 0.9045 - auc: 0.9555 - val_loss: 0.0573 - val_accuracy: 0.9025 - val_precision: 0.9025 - val_recall: 0.9025 - val_auc: 0.9485 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0524 - accuracy: 0.9042 - precision: 0.9042 - recall: 0.9042 - auc: 0.9570\n",
      "Epoch 45: val_loss did not improve from 0.05686\n",
      "117/117 [==============================] - 94s 806ms/step - loss: 0.0524 - accuracy: 0.9042 - precision: 0.9042 - recall: 0.9042 - auc: 0.9570 - val_loss: 0.0596 - val_accuracy: 0.9015 - val_precision: 0.9015 - val_recall: 0.9015 - val_auc: 0.9490 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0519 - accuracy: 0.9023 - precision: 0.9023 - recall: 0.9023 - auc: 0.9585\n",
      "Epoch 46: val_loss did not improve from 0.05686\n",
      "117/117 [==============================] - 102s 868ms/step - loss: 0.0519 - accuracy: 0.9023 - precision: 0.9023 - recall: 0.9023 - auc: 0.9585 - val_loss: 0.0583 - val_accuracy: 0.9006 - val_precision: 0.9006 - val_recall: 0.9006 - val_auc: 0.9486 - lr: 2.0000e-05\n",
      "Epoch 47/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0519 - accuracy: 0.9042 - precision: 0.9042 - recall: 0.9042 - auc: 0.9585\n",
      "Epoch 47: val_loss did not improve from 0.05686\n",
      "117/117 [==============================] - 93s 793ms/step - loss: 0.0519 - accuracy: 0.9042 - precision: 0.9042 - recall: 0.9042 - auc: 0.9585 - val_loss: 0.0585 - val_accuracy: 0.8996 - val_precision: 0.8996 - val_recall: 0.8996 - val_auc: 0.9476 - lr: 2.0000e-05\n",
      "Epoch 48/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 0.9047 - precision: 0.9047 - recall: 0.9047 - auc: 0.9595\n",
      "Epoch 48: val_loss did not improve from 0.05686\n",
      "117/117 [==============================] - 92s 782ms/step - loss: 0.0513 - accuracy: 0.9047 - precision: 0.9047 - recall: 0.9047 - auc: 0.9595 - val_loss: 0.0576 - val_accuracy: 0.9015 - val_precision: 0.9015 - val_recall: 0.9015 - val_auc: 0.9483 - lr: 2.0000e-05\n",
      "Epoch 49/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0519 - accuracy: 0.9055 - precision: 0.9055 - recall: 0.9055 - auc: 0.9577\n",
      "Epoch 49: val_loss did not improve from 0.05686\n",
      "117/117 [==============================] - 88s 750ms/step - loss: 0.0519 - accuracy: 0.9055 - precision: 0.9055 - recall: 0.9055 - auc: 0.9577 - val_loss: 0.0575 - val_accuracy: 0.9015 - val_precision: 0.9015 - val_recall: 0.9015 - val_auc: 0.9475 - lr: 2.0000e-05\n",
      "Epoch 50/50\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.0516 - accuracy: 0.9039 - precision: 0.9039 - recall: 0.9039 - auc: 0.9589\n",
      "Epoch 50: val_loss improved from 0.05686 to 0.05682, saving model to models\\cnn_model_split_70_20_10.h5\n",
      "117/117 [==============================] - 100s 855ms/step - loss: 0.0516 - accuracy: 0.9039 - precision: 0.9039 - recall: 0.9039 - auc: 0.9589 - val_loss: 0.0568 - val_accuracy: 0.9044 - val_precision: 0.9044 - val_recall: 0.9044 - val_auc: 0.9500 - lr: 2.0000e-05\n",
      "basic_cnn_model history for split_70_20_10 saved as models/cnn_model_split_70_20_10.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np \n",
    "\n",
    "def train_and_save_history(train_generator, valid_generator, split_name=\"split_70_20_10\", epochs=50, batch_size=32):\n",
    "    steps_per_epoch = train_generator.samples // batch_size\n",
    "    validation_steps = valid_generator.samples // batch_size\n",
    "\n",
    "   # compile model\n",
    "    model = simple_cnn_model() \n",
    "\n",
    "    callbacks = compile_model(model, split_name)\n",
    "\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=valid_generator,\n",
    "        validation_steps=validation_steps,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    # save history\n",
    "    history_path = f\"models/cnn_model_{split_name}.pkl\"\n",
    "    with open(history_path, 'wb') as f:  \n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    print(f\"basic_cnn_model history for {split_name} saved as {history_path}\")\n",
    "\n",
    "\n",
    "# train `split_70_20_10` and save history\n",
    "train_and_save_history(train_generator_70_20_10, valid_generator_70_20_10, split_name=\"split_70_20_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dfd1759-36d4-4a32-9fad-8ae52179d410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 8s 402ms/step - loss: 0.0556 - accuracy: 0.9118 - precision: 0.9118 - recall: 0.9118 - auc: 0.9565\n",
      "Test Loss: 0.05560336261987686\n",
      "Test Accuracy: 0.9118198752403259\n",
      "Test Precision: 0.9118198752403259\n",
      "Test Recall: 0.9118198752403259\n",
      "Test AUC: 0.9565294981002808\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# load model and loss function\n",
    "model = load_model(\n",
    "    'models/cnn_model_split_70_20_10.h5',\n",
    "    custom_objects={'focal_loss_fixed': focal_loss(gamma=2., alpha=0.75)}  \n",
    ")\n",
    "\n",
    "# evaluation\n",
    "test_loss, test_accuracy, test_precision, test_recall, test_auc = model.evaluate(test_generator_70_20_10, verbose=1)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Precision: {test_precision}\")\n",
    "print(f\"Test Recall: {test_recall}\")\n",
    "print(f\"Test AUC: {test_auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ff9ab7f-5a78-4ffe-9fbf-8cf9bb7d06be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Sensitivity (Recall): 0.9977272727272727\n",
      "Specificity: 0.2786885245901639\n",
      "Confusion matrix saved at: C:\\Users\\xiaog\\Desktop\\Project\\Datasets\\dataset\\Performance\\CNN\\confusion_matrix_inception.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "save_dir = r\"C:\\Users\\xiaog\\Desktop\\Project\\Datasets\\dataset\\Performance\\CNN\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "test_steps = test_generator_70_20_10.samples // test_generator_70_20_10.batch_size  \n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# get prediction result\n",
    "for _ in range(test_steps):\n",
    "    x, y = test_generator_70_20_10.next()\n",
    "    predictions = model.predict(x)\n",
    "    \n",
    "    # get true label\n",
    "    y_true.extend(np.argmax(y, axis=1)) \n",
    "    # get prediction label\n",
    "    y_pred.extend(np.argmax(predictions, axis=1))\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Calculate sensitivity (Recall) and specificity\n",
    "TP = cm[1, 1] \n",
    "TN = cm[0, 0]  \n",
    "FP = cm[0, 1]  \n",
    "FN = cm[1, 0]  \n",
    "\n",
    "sensitivity = TP / float(TP + FN)\n",
    "specificity = TN / float(TN + FP)\n",
    "\n",
    "print(f'Sensitivity (Recall): {sensitivity}')\n",
    "print(f'Specificity: {specificity}')\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Defect', 'Defect'], yticklabels=['No Defect', 'Defect'])\n",
    "plt.title('Confusion Matrix of CNN', fontsize=14)\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.ylabel('True', fontsize=12)\n",
    "\n",
    "# Save the confusion matrix plot\n",
    "confusion_matrix_path = os.path.join(save_dir, 'confusion_matrix_inception.png')\n",
    "plt.savefig(confusion_matrix_path, dpi=600, bbox_inches='tight')\n",
    "\n",
    "# Print the saved path\n",
    "print(f\"Confusion matrix saved at: {confusion_matrix_path}\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ceb6906-5c3f-4539-bf80-726e2ffc153f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "F1 Score: 0.9581\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "test_steps = test_generator_70_20_10.samples // test_generator_70_20_10.batch_size\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for _ in range(test_steps):\n",
    "    x, y = test_generator_70_20_10.next()\n",
    "    predictions = model.predict(x)\n",
    "    y_true.extend(np.argmax(y, axis=1))              \n",
    "    y_pred.extend(np.argmax(predictions, axis=1))   \n",
    "\n",
    "f1 = f1_score(y_true, y_pred, average='binary') \n",
    "print(f'F1 Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d195a8-89eb-4f5e-a49c-c0912cbd4042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fda56f-fe14-4095-ad95-4972c58ca807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19967301-a778-43c5-afe4-7f433f2ac85a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8e63c7-d3ca-4e80-8ac2-1a2a5ad05eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57a7b36-1605-4298-a16f-141289dccb01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c10a90-cfe7-422d-92a7-5d9ed9f5e154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564517f0-c548-4932-a4e4-6b0346c4eff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fe140e-da90-406a-86a4-5d59f21588da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
